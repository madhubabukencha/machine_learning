{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81cca6a",
   "metadata": {},
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif; \n",
    "          text-align: center;\">\n",
    "          Machine Learning Terminology</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec7539-744d-44a5-af3d-dfc532d96595",
   "metadata": {},
   "source": [
    "#### Training Example\n",
    "A row in a table representing the dataset and synonymous with an obervation, record, instance or sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52406a-224b-43a0-9155-4917ff1e46ef",
   "metadata": {},
   "source": [
    "#### Training\n",
    "Model fitting, for parametric models similar to parameter estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0114173c-ed5b-44e8-bf8b-c56448842bf8",
   "metadata": {},
   "source": [
    "#### Features(denoted by X)\n",
    "A column in data table or data matrix. Synonymus with predictor, variable, input, attribute or covariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6d33b-1bfe-40eb-9ecd-104f03746a58",
   "metadata": {},
   "source": [
    "#### Target(denoted by y)\n",
    "Synonymous with outcome, output, response variable, dependent variable, (class) lable and ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0463ca-f49a-49a9-9a6b-98095bcde5a0",
   "metadata": {},
   "source": [
    "#### Loss Function\n",
    "Often used synonymously with a <i>cost</i> function. Sometimes loss function also called <i>error</i> function. In some literatures the term \"loss\" refers to the loss measured for single data point and the <i>cost</i> is a measurement that computes the loss(average or summed) over the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d432c2-5f28-4f61-8a46-04c18c932bef",
   "metadata": {},
   "source": [
    "#### Noise\n",
    "Noise (in the data science space) is unwanted data items, features or records which donâ€™t help in explaining the feature itself, or the relationship between feature & target. Noise often causes the algorithms to miss out patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358ca874-f052-4784-8e67-f8fb69d3673c",
   "metadata": {},
   "source": [
    "#### Sampling Noise\n",
    "If the sample data is too small, we will have <i>sampling noise</i>. In my opinion it happens because if the data is small it not possible for the model to acurately generalize on data. If we apply this model on some new data point points this model might get fail becuase it consumed noise data from the small data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c796ca37-c5ab-40bb-a7fa-94259d6a0e1f",
   "metadata": {},
   "source": [
    "#### Sampling Bias\n",
    "Even very large samples can be nonrepesentative(becomes not proper data sets) if the sampling method is flawed. So we need split the dataset to avoid Sampling Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a7dff-4b26-4a24-8942-fd6c1d69bb3e",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "It is a process of selecting the most useful features to train on among existing features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5e8e1-a0a6-41b8-89cf-6bd7a33fd3c8",
   "metadata": {},
   "source": [
    "#### Feature Extraction\n",
    "It is a process of combining existing features to produce more useful one. Dimensionality reduction algorithms can help to achieve this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcf5ba8-b518-4a49-aff3-d4a2689d452e",
   "metadata": {},
   "source": [
    "#### Overfitting the Training Data\n",
    "Overfitting means that the model performs well on the training data, but it does not generalize well. Due to this if you give any new point it might fail to predict proper outcome for that.<br>\n",
    "Overfitting happens when the model is too complex relative to the amount and noisness of the training data. To fix this we can do\n",
    "<ul style=\"list-style-type: circle;\">\n",
    "            <li>Simplify the model by selecting one with fewer parameters by reducing the number of attributes in the training data or by constraining the model</li>\n",
    "            <li>\n",
    "                Gather more training data\n",
    "            </li>\n",
    "            <li>\n",
    "                Reduce the noise in the training data(e.g., fix data errors and remove outliers)\n",
    "            </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b0ca3-061c-4c30-9400-faf05cf4574e",
   "metadata": {},
   "source": [
    "#### Underfitting the Training Data\n",
    "Underfitting occures when your model is too simple to learn underlying structure of the data. \n",
    "Here are the main options for fixing this problem,\n",
    "<ul style=\"list-style-type: circle;\">\n",
    "    <li> Select a more powerful model, with morer parameters</li>\n",
    "    <li> Feed better features to the learning algorithm (feature Engineering)</li>\n",
    "    <li> Reduce the constraints on the model(e.g., reduce the regularization hyperparmeter)\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ef676-0b1d-494f-bcf6-99882841f142",
   "metadata": {},
   "source": [
    "#### Hyper Parameter\n",
    "A machine learning model has multiple parameters that are not trained by the training set. These parameters control the accuracy of the model. Therefore, the hyperparameters are particularly important in a data science project. The hyperparameters are configured up-front and are provided by the caller of the model before the model is trained. <br>\n",
    " the learning rate of a neural network is a hyperparameter because it is set by the caller before the training data is fed to the model. On the other hand, the weights of a neural network are not its hyperparameters because they are trained by the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95312ab5-d85f-4f8e-983b-b1d2e3d3648f",
   "metadata": {},
   "source": [
    "#### Regularization\n",
    "Constraining a model to make simpler and reduce the risk of overfitting is called <i> Regularization</i>. The amount of regularization to apply during learning can be controlled by a <i>Hyper parameter</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664af265-2a8e-4b30-9b27-6afbbbfc6d16",
   "metadata": {},
   "source": [
    "#### Generalization Error\n",
    "You train your model using the training set and test it using the test set. The error rate on new cases is called the <i> generalization error (or <i>out-of-sample</i>error) </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821690b-e543-4c4b-8d32-ae7eaee55376",
   "metadata": {},
   "source": [
    "#### Validation Set and It's importance\n",
    "You hold out a a part of the training set to evaluate serveral candidate models and select the best one. The new held-out set is called the <i> validatation set </i>(or sometimes the <i>development set</i>, or <i>dev set</i>). \n",
    "At the end you train multiple models with various hyper parameters on the reduced training set(i.e the full trainingset minus the validation set), and you select the model that performs the on the validation set. <br>\n",
    "To reduce generalization error, also train your model by including both train and validation data. whatever model that performs well on the data chose that model and validate using test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3036be-73bc-4490-adad-ce156e629fdf",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters. It is an exhaustive search that is performed on a the specific parameter values of a model. The model is also known as an estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3631b-1050-4b54-b48a-6ab61ddeec69",
   "metadata": {},
   "source": [
    "#### Learning Rate\n",
    "Another important parameter of online learning system is how fast they should adapt to new changing data, this called the Learning Rate. If you set learning rate is high then your system will rapidly adapt to new data but it will also tend to quickly forget the old data. If you set learning rate low then it will learn slowly and it will also be less sensitive to noise in the new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58946c9e-48c8-483b-aa8c-834cc8553283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
