{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81cca6a",
   "metadata": {},
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif; \n",
    "          text-align: center;\">\n",
    "          Machine Learning Terminology</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c028044",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>\n",
    "        <b>Training Example:</b> <br>\n",
    "        A row in a table representing the dataset and synonymous with an \n",
    "        obervation, record, instance or sample\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Training:</b><br>\n",
    "        Model fitting, for parametric models similar to parameter estimation.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Feature(x):</b><br>\n",
    "        A column in data table or data matrix. Synonymus with predictor, variable,\n",
    "        input, attribute or covariate\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Target(y):</b> <br>\n",
    "        Synonymous with outcome, output, response variable, dependent variable, (class) lable\n",
    "        and ground truth\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Loss Function:</b><br>\n",
    "        Often used synonymously with a <i>cost</i> function. Sometimes loss function also\n",
    "        called <i>error</i> function. In some literatures the term \"loss\" refers to the loss measured for single data\n",
    "        point and the <i>cost</i> is a measurement that computes the loss(average or summed) over the entire dataset.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Noise:</b><br>\n",
    "        Noise (in the data science space) is unwanted data items, features or records which donâ€™t help in explaining\n",
    "        the feature itself, or the relationship between feature & target. Noise often causes the algorithms to miss\n",
    "        out patterns in the data.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Sampling Noise:</b><br>\n",
    "        If the sample data is too small, we will have <i>sampling noise</i>. In my opinion it happens because if the \n",
    "        data is small it not possible for the model to acurately generalize on data. If we apply this model on some new data point points\n",
    "        this model might get fail becuase it consumed noise data from the small data set.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b> Sampling Bias: </b><br>\n",
    "        Even very large samples can be nonrepesentative(becomes not proper data sets) if the sampling method is flawed.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b> Feature Selection </b><br>\n",
    "        It is a process of selecting the most useful features to train on among existing features.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b> Feature Extraction </b><br>\n",
    "        It is a process of combining existing features to produce more useful one. Dimensionality reduction algorithms can help to achieve this task.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b> Overfitting the Training Data </b><br>\n",
    "        Overfitting means that the model performs well on the training data, but it does not generalize well. Due to this if you give any new point it might fail to predict proper outcome for that.<br>\n",
    "        Overfitting happens when the model is too complex relative to the amount and noisness of the training data. To fix this we can do,<br>\n",
    "        <ul style=\"list-style-type: circle;\">\n",
    "            <li>Simplify the model by selecting one with fewer parameters by reducing the number of attributes in the training data or by constraining the model</li>\n",
    "            <li>\n",
    "                Gather more training data\n",
    "            </li>\n",
    "            <li>\n",
    "                Reduce the noise in the training data(e.g., fix data errors and remove outliers)\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Regularization and Hyper Parameter</b><br>\n",
    "        Constraining a model to make simpler and reduce the risk of overfitting is called <i> Regularization</i>. The amount of regularization to apply during learning can be controlled by a <i>Hyper parameter</i>. This hyperparameter is a parameter of the learning algorithm itself, not of the model. It must be set prior to training and remains constant during training.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b> Underfitting the Training Data</b><br>\n",
    "        Underfitting occures when your model is too simple to learn underlying structure of the data. \n",
    "        Here are the main options for fixing this problem,\n",
    "        <ul style=\"list-style-type: circle;\">\n",
    "            <li> Select a more powerful model, with morer parameters</li>\n",
    "            <li> Feed better features to the learning algorithm (feature Engineering)</li>\n",
    "            <li> Reduce the constraints on the model(e.g., reduce the regularization hyperparmeter)\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <b> Generalization Error </b><br>\n",
    "        You train your model using the training set an the test it using the test set. The error rate on new cases is called the <i> generalization error (or <i>out-of-sample</i>error) </i>\n",
    "    </li>\n",
    "    <li>\n",
    "        <b> Validation Set and It's importance </b><br>\n",
    "        You hold out a a part of the training set to evaluate serveral candidate models and select the best one. The new held-out set is called the <i> validatation set </i>(or sometimes the <i>development set</i>, or <i>dev set</i>). \n",
    "        At the end you train multiple models with various hyper parameters on the reduced training set(i.e the full trainingset minus the validation set), and you select the model that performs the on the validation set. <br>\n",
    "        To reduce generalization error, also train your model by including both train and validation data. whatever model that performs well on the data chose that model and validate using test data. \n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d9f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
