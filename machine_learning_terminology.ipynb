{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81cca6a",
   "metadata": {},
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif; \n",
    "          text-align: center;\">\n",
    "          Machine Learning Terminology</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec7539-744d-44a5-af3d-dfc532d96595",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Training Example</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       A row in a table representing the dataset and synonymous with an obervation, record, instance or sample\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0114173c-ed5b-44e8-bf8b-c56448842bf8",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Features (denoted by X)</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       A column in data table or data matrix. Synonymus with predictor, variable, input, attribute or covariate\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6d33b-1bfe-40eb-9ecd-104f03746a58",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Target (denoted by y)</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Synonymous with outcome, output, response variable, dependent variable, (class) lable and ground truth\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31622445-94f3-4d49-829c-8d5a2130df50",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Training and Test Set</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762bc0d4-d9ee-4ad9-8b90-93280d68c213",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       While working with machine learning algorithms, we usually split data into <i>Training Set</i> and\n",
    "       <i>Test Set</i>. Training set is used for training our model. Test set is used to know how well our\n",
    "       model performs on new unseen data.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94289650-682b-4bc1-b0df-7ed665666b9f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Hypothesis</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf6a96f-8159-4543-893d-b96bf5f84c9b",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "     a hypothesis is an educated guess or an idea that you come up with to explain something you observe. It's like\n",
    "     a tentative answer to a question or a possible solution to a problem.<br>\n",
    "     Imagine you're walking down the street and you see a puddle of water. You might wonder where the water came from. \n",
    "     You could come up with a few different hypotheses to explain it, such as:<br>\n",
    "     <ul>\n",
    "         <li>It rained recently.</li>\n",
    "         <li>Someone spilled water.</li>\n",
    "         <li>There's a leak in a pipe.</li>\n",
    "     </ul>\n",
    "    These are all hypotheses because they are possible explanations for the puddle of water. However, they are\n",
    "    not proven facts yet. You would need to do some more investigating, such as looking for rain clouds, checking\n",
    "    for spills, or examining pipes, to determine which hypothesis is most likely correct.<br>\n",
    "    Hypotheses are important in science because they allow us to test our ideas and explanations. By conducting\n",
    "    experiments and collecting data, we can see if our hypotheses are supported or refuted. This helps us to\n",
    "    learn more about the world around us and to develop new theories and explanations.\n",
    "  </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d6f78-b58c-4866-9471-3e9ede9e8aae",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Validation Set</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5316fe35-a9f7-4c89-8ff5-a5c51b6ffc6a",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Let us assume that a model has been trained by fine-tuning its hyperparameters to achieve better results on the test set. However, there is a possibility that this model only performs well on this specific test set and may not generalize well to new instances. To mitigate this risk, we should create a <b>validation set</b> (or sometimes the <i>development set</i>, or <i>dev set</i>) from the training set. The model will then be trained on the rest of the training set and validated using the validation set. We select the model that performs best on the validation set. Later, we combine both the rest of the training set and the validation set to build a final model, which is then validated using the test set. This process helps to ensure that the model is not overfitting to the training set and that it is able to generalize well to new instances.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ef676-0b1d-494f-bcf6-99882841f142",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Hyper Parameter</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       A machine learning model has multiple parameters that are not trained by the training set. These parameters control\n",
    "       the accuracy of the model. Therefore, the hyperparameters are particularly important in a data science project. The\n",
    "       hyperparameters are configured up-front and are provided by the caller of the model before the model is trained. <br><br>\n",
    "       The <i>learning rate</i> of a neural network is a hyperparameter because it is set by the caller before the training data is\n",
    "       fed to the model. On the other hand, the <i>weights</i> of a neural network are not its hyperparameters because they are trained\n",
    "       by the training dataset\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0463ca-f49a-49a9-9a6b-98095bcde5a0",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Loss Function</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Often used synonymously with a <i>cost</i> function. Sometimes loss function also called <i>error</i> function. In some literatures the term \"loss\" refers to the loss measured for single data point and the <i>cost</i> is a measurement that computes the loss(average or summed) over the entire dataset.\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d432c2-5f28-4f61-8a46-04c18c932bef",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Noise</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Noise (in the data science space) is unwanted data items, features or records which don’t help in explaining the feature itself, or the relationship between feature & target. Noise often causes the algorithms to miss out patterns in the data.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358ca874-f052-4784-8e67-f8fb69d3673c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Sampling Noise</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       If the sample data is too small, we will have <i>sampling noise</i>. In my opinion it happens because if the data is small it not possible for the model to acurately generalize on data. If we apply this model on some new data point points this model might get fail becuase it consumed noise data from the small data set.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c796ca37-c5ab-40bb-a7fa-94259d6a0e1f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Sampling Bias</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Even very large samples can be nonrepesentative(becomes not proper data sets) if the sampling method is flawed. So we need split the dataset to avoid Sampling Bias\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a7dff-4b26-4a24-8942-fd6c1d69bb3e",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Feature Selection</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       It is a process of selecting the most useful features to train on among existing features.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5e8e1-a0a6-41b8-89cf-6bd7a33fd3c8",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Feature Extraction</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       It is a process of combining existing features to produce more useful one. Dimensionality reduction algorithms can help to achieve this task.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcf5ba8-b518-4a49-aff3-d4a2689d452e",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Overfitting the Training Data</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Overfitting means that the model performs well on the training data, but it does not generalize well. Due to this if you give\n",
    "       any new point it might fail to predict proper outcome for that.<br>\n",
    "       Overfitting happens when the model is too complex relative to the amount and noisness of the training data. To fix this we can do\n",
    "       <ul style=\"list-style-type: circle;\">\n",
    "           <li>\n",
    "               Simplify the model by selecting one with fewer parameters by reducing the number of attributes\n",
    "               in the training data or by constraining the model\n",
    "           </li>\n",
    "           <li>\n",
    "               Gather more training data\n",
    "           </li>\n",
    "           <li>\n",
    "               Reduce the noise in the training data(e.g., fix data errors and remove outliers)\n",
    "           </li>\n",
    "       </ul>\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b0ca3-061c-4c30-9400-faf05cf4574e",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Underfitting the Training Data</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Underfitting occures when your model is too simple to learn underlying structure of the data. \n",
    "       Here are the main options for fixing this problem,\n",
    "    <ul style=\"list-style-type: circle;\">\n",
    "        <li> Select a more powerful model, with morer parameters</li>\n",
    "        <li> Feed better features to the learning algorithm (feature Engineering)</li>\n",
    "        <li> Reduce the constraints on the model(e.g., reduce the regularization hyperparmeter)\n",
    "    </ul>\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95312ab5-d85f-4f8e-983b-b1d2e3d3648f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Regularization</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Constraining a model to make simpler and reduce the risk of overfitting is called <i> Regularization</i>. The amount\n",
    "       of regularization to apply during learning can be controlled by a <i>Hyper parameter</i>\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664af265-2a8e-4b30-9b27-6afbbbfc6d16",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Generalization Error(or out-of-sample-error)</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       You train your model using the training set and test it using the test set. The error rate on new cases is called the <i>\n",
    "       generalization error (or <i>out-of-sample</i>error) </i>\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3036be-73bc-4490-adad-ce156e629fdf",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Grid Search</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters. It is an exhaustive\n",
    "       search that is performed on a the specific parameter values of a model. The model is also known as an estimator\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3631b-1050-4b54-b48a-6ab61ddeec69",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Learning Rate</span>\n",
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Another important parameter of online learning system is how fast they should adapt to new changing data, this called\n",
    "       the Learning Rate. If you set learning rate is high then your system will rapidly adapt to new data but it will also \n",
    "       tend to quickly forget the old data. If you set learning rate low then it will learn slowly and it will also be less\n",
    "       sensitive to noise in the new data. \n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac99ae-b0ca-4c8c-a681-e4e7772d1baa",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Ground Truth</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a397a0a5-d044-4126-8741-22ee134672ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       <p>The term “ground truth” refers to the actual nature of the problem that is the target of a machine learning model, \n",
    "           reflected by the relevant data sets associated with the use case in question. In supervised machine learning models,\n",
    "           ground truth is the correct or “true” answer to a specific problem or question. It can be used to evaluate the\n",
    "           performance of a machine learning model, by comparing the model’s predictions with the ground truth.\n",
    "       </p>\n",
    "       <p>Here are some examples of ground truth:</p>\n",
    "        <ul>\n",
    "            <li>In an image classification problem, the ground truth might be the label of each image\n",
    "                (e.g., cat, dog, sheep).</li>\n",
    "            <li>In a natural language processing problem, the ground truth might be the sentiment of a sentence\n",
    "                (e.g., positive, negative, neutral).</li>\n",
    "            <li>In a speech recognition problem, the ground truth might be the transcription of a spoken utterance.</li>\n",
    "        </ul>\n",
    "       <p>Ground truth data can be collected in a variety of ways, including:</p>\n",
    "        <ul>\n",
    "            <li>Manually labeling data by experts.</li>\n",
    "            <li>Using crowdsourcing platforms to label data.</li>\n",
    "            <li>Using self-supervised learning techniques to generate ground truth data.</li>\n",
    "        </ul>\n",
    "        <p>The quality of ground truth data is critical to the performance of a machine learning model. If the ground\n",
    "            truth data is inaccurate or incomplete, the model will likely produce inaccurate predictions.</p>\n",
    "        <p>Here are some challenges associated with collecting ground truth data:</p>\n",
    "        <ul>\n",
    "            <li>It can be time-consuming and expensive to collect ground truth data manually.</li>\n",
    "            <li>It can be difficult to find experts who have the knowledge and skills necessary to label\n",
    "                data accurately.</li>\n",
    "            <li>Crowdsourcing platforms can be unreliable, as the quality of the labels can vary depending on the\n",
    "                quality of the workers who are doing the labeling.</li>\n",
    "            <li>Self-supervised learning techniques can be computationally expensive and may not always produce\n",
    "                accurate ground truth data.</li>\n",
    "        </ul>\n",
    "        <p>Despite the challenges, ground truth data is essential for training and evaluating machine learning models\n",
    "            . By collecting high-quality ground truth data, machine learning practitioners can build models that\n",
    "            are more accurate and reliable.</p>\n",
    "    </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e734e-520c-4800-87e5-4aa3941abe9f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Feature Scaling</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72230bca-5283-4776-a06a-132f15690dec",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Feature scaling is a data preprocessing technique used to transform the values of features or variables in a dataset to a similar scale. The purpose is to ensure that all features contribute equally to the model and to avoid the domination of features with larger values.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb4860-2885-49b4-99b7-41541ba66182",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Normalization</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574d0fcb-b65f-480c-a03d-db23dded7617",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d4e9b-16c2-4b62-ae91-be4852e3be0f",
   "metadata": {},
   "source": [
    "$$X_{norm} = \\frac{X - min(X)}{max(X)-min(X)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ef5a4-631b-4c51-9f14-aa23114e6426",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3C4048; font-weight: bold; font-size: 18px; font-family: Gill Sans, sans-serif;\">Standardization</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c05bf0-fb73-4709-ab37-bc0686cc980a",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Standardization is another scaling method where the values are centered around the mean with a unit standard deviation. This means that the mean of the attribute becomes zero, and the resultant distribution has a unit standard deviation.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88125f-aa32-4186-ad38-b854e36e4460",
   "metadata": {},
   "source": [
    "$$X_{stand}=\\frac{X-mean(X)}{std(X)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e528d66-1294-477c-866a-bf360e03ea38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
